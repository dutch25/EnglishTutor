from fastapi import APIRouter, File, UploadFile, Form
import shutil, os, json, subprocess, re, difflib, wave, json as js, requests
from pydub import AudioSegment, effects
from vosk import Model, KaldiRecognizer
from dotenv import load_dotenv

# ====== ğŸ”§ Cáº¥u hÃ¬nh ======
router = APIRouter()
UPLOAD_FOLDER = "./uploads"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
MODEL_PATH = "./models/vosk-en"
ESPEAK_PATH = r"C:\Program Files\eSpeak NG\espeak-ng.exe"

# ====== ğŸ”‘ Load API Key GPT ======
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ====== ğŸš€ Load model Vosk ======
if not os.path.exists(MODEL_PATH):
    raise RuntimeError("âŒ KhÃ´ng tÃ¬m tháº¥y model Vosk! Giáº£i nÃ©n model vÃ o ./models/vosk-en")
vosk_model = Model(MODEL_PATH)

# ====== ğŸ”¤ Xá»­ lÃ½ IPA ======
def get_ipa(text: str) -> str:
    if not text.strip():
        return ""
    try:
        res = subprocess.run([ESPEAK_PATH, "-v", "en", "-q", "--ipa=3", text],
                             capture_output=True, text=True, encoding="utf-8", check=True)
        return res.stdout.strip()
    except Exception as e:
        print("âŒ Lá»—i IPA:", e)
        return ""

def split_ipa(ipa: str):
    return re.findall(r"[ËˆËŒ]?[a-zÉ‘É”Ã¦É™ÉªÊŠeÊŒÎ¸Ã°Å‹ÊƒÊ’Ê”É¡É¾ÌƒË]+|[.,!?;]", ipa.strip())

def compare_ipa_colored(target_ipa: str, user_ipa: str):
    matcher = difflib.SequenceMatcher(None, split_ipa(target_ipa), split_ipa(user_ipa))
    html = ""
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == "equal":
            html += ''.join(f'<span style="color:green">{p}</span>' for p in split_ipa(user_ipa)[j1:j2])
        elif tag in ("replace", "insert"):
            html += ''.join(f'<span style="color:red;text-decoration:underline">{p}</span>' for p in split_ipa(user_ipa)[j1:j2])
        elif tag == "delete":
            html += ''.join(f'<span style="background:yellow">{p}</span>' for p in split_ipa(target_ipa)[i1:i2])
    return round(matcher.ratio() * 100), html

def compare_text_colored(original, spoken):
    res = ""
    max_len = max(len(original), len(spoken))
    for i in range(max_len):
        o = original[i] if i < len(original) else " "
        s = spoken[i] if i < len(spoken) else " "
        res += f'<span style="color:{"green" if o == s else "red"}">{o}</span>'
    return res

# ====== ğŸ§ Xá»­ lÃ½ Ã¢m thanh ======
def preprocess_audio(input_path, output_path):
    try:
        audio = AudioSegment.from_file(input_path)
        audio = effects.normalize(audio).set_channels(1).set_frame_rate(16000)
        audio.export(output_path, format="wav", codec="pcm_s16le")
        print(f"âœ… ÄÃ£ convert {input_path} â†’ {output_path}, size={os.path.getsize(output_path)} bytes")
    except Exception as e:
        print("âŒ Lá»—i khi xá»­ lÃ½ audio:", e)

def transcribe_audio(file_path):
    clean_path = file_path.replace(".webm", "_clean.wav")
    preprocess_audio(file_path, clean_path)

    if not os.path.exists(clean_path) or os.path.getsize(clean_path) < 1000:
        print("âš ï¸ File WAV trá»‘ng hoáº·c quÃ¡ nhá»!")
        return ""

    print(f"ğŸ§ Báº¯t Ä‘áº§u nháº­n dáº¡ng vá»›i Vosk: {clean_path}")
    wf = wave.open(clean_path, "rb")
    rec = KaldiRecognizer(vosk_model, wf.getframerate())
    rec.SetWords(True)

    text = ""
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if rec.AcceptWaveform(data):
            res = js.loads(rec.Result())
            print("ğŸ‘‰ Partial:", res.get("text", ""))
            text += " " + res.get("text", "")
    res = js.loads(rec.FinalResult())
    print("ğŸ‘‰ Final:", res.get("text", ""))
    text += " " + res.get("text", "")
    wf.close()

    text = text.strip()
    if not text:
        print("âš ï¸ KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c giá»ng nÃ³i!")
    return text

# ====== ğŸ“¥ API Upload ======
@router.post("/api/upload/")
async def upload_audio(file: UploadFile = File(...), original_text: str = Form(...)):
    path = os.path.join(UPLOAD_FOLDER, file.filename)
    with open(path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    transcript = transcribe_audio(path)
    if not transcript:
        return {"error": "âš ï¸ KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c giá»ng nÃ³i!", "transcript": ""}

    original_ipa = get_ipa(original_text)
    user_ipa = get_ipa(transcript)
    ipa_score, ipa_html = compare_ipa_colored(original_ipa, user_ipa)

    return {
        "transcript": transcript,
        "original_ipa": original_ipa,
        "user_ipa_raw": user_ipa,
        "user_ipa_colored": ipa_html,
        "sentence_colored": compare_text_colored(original_text, transcript),
        "ipa_score": ipa_score
    }

# ====== ğŸ“š API Láº¥y cÃ¢u tá»« JSON ======
JSON_PATH = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../frontend/src/assets/data/conversations.json")
)

def load_sentences(topic: str = None):
    with open(JSON_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)
    result = []
    for key, value in data.items():
        if topic and key.lower() != topic.lower():
            continue
        for s in value["sentences"]:
            result.append({
                "topic": key,
                "icon": value.get("icon", ""),
                "english": s.get("english", ""),
                "vietnamese": s.get("vietnamese", ""),
                "pronunciation": s.get("pronunciation", "")
            })
    return result

@router.get("/api/sentences")
def get_sentences(topic: str = None):
    return {"sentences": load_sentences(topic)}

# ====== ğŸ“¥ API Láº¥y IPA ======
@router.post("/api/get_ipa")
def api_get_ipa(body: dict):
    return {"ipa": get_ipa(body.get("text", ""))}

# ====== ğŸ¤– API Feedback GPT (phÃ¢n tÃ­ch Ä‘iá»ƒm máº¡nh/Ä‘iá»ƒm yáº¿u) ======
@router.post("/api/feedback")
def feedback(body: dict):
    transcript = body.get("transcript", "")
    target = body.get("target", "")

    if not OPENAI_API_KEY:
        return {"feedback": "âš ï¸ KhÃ´ng tÃ¬m tháº¥y OpenAI API Key."}

    prompt = f"""
Báº¡n lÃ  giÃ¡o viÃªn phÃ¡t Ã¢m tiáº¿ng Anh cho ngÆ°á»i Viá»‡t. 
Há»c viÃªn muá»‘n nÃ³i: "{target}"
AI nghe Ä‘Æ°á»£c: "{transcript}"

HÃ£y:
1. âœ… NÃªu Äiá»ƒm máº¡nh trong phÃ¡t Ã¢m.
2. âŒ Chá»‰ ra Äiá»ƒm yáº¿u cá»¥ thá»ƒ (Ã¢m sai, thiáº¿u nháº¥n, ngá»¯ Ä‘iá»‡u).
3. ğŸ’¡ ÄÆ°a ra máº¹o cáº£i thiá»‡n chi tiáº¿t.


Pháº£i cÃ³ 3 má»¥c rÃµ rÃ ng Ä‘iá»ƒm máº¡nh, Ä‘iá»ƒm yáº¿u vÃ  máº¹o cáº£i thiá»‡n
Tráº£ lá»i ngáº¯n gá»n, rÃµ rÃ ng, dá»… hiá»ƒu vÃ  khÃ´ng thÃªm cÃ¡c dáº¥u ** á»Ÿ Ä‘áº§u cÃ¢u.
"""

    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    payload = {
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.6,
        "max_tokens": 220
    }

    try:
        res = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload, timeout=15)
        if res.status_code == 200:
            data = res.json()
            return {"feedback": data.get("choices", [{}])[0].get("message", {}).get("content", "âš ï¸ KhÃ´ng cÃ³ pháº£n há»“i.")}
        else:
            print("âŒ GPT API lá»—i:", res.text)
            return {"feedback": "âš ï¸ AI khÃ´ng tráº£ lá»i, thá»­ láº¡i sau."}
    except Exception as e:
        print("âŒ Lá»—i gá»i GPT API:", e)
        return {"feedback": "âš ï¸ KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c AI."}
